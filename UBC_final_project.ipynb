{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 45867,
          "databundleVersionId": 6924515,
          "sourceType": "competition"
        },
        {
          "sourceId": 6984590,
          "sourceType": "datasetVersion",
          "datasetId": 4014175
        }
      ],
      "dockerImageVersionId": 30587,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PACKAGE IMPORT**"
      ],
      "metadata": {
        "id": "7Nu5eGCbEWxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torcheval\n",
        "# !pip install timm\n",
        "# !pip install grad-cam"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:13:43.447730Z",
          "iopub.execute_input": "2023-12-07T16:13:43.448517Z",
          "iopub.status.idle": "2023-12-07T16:13:56.483320Z",
          "shell.execute_reply.started": "2023-12-07T16:13:43.448481Z",
          "shell.execute_reply": "2023-12-07T16:13:56.482334Z"
        },
        "trusted": true,
        "id": "J7lmYNb4EWxl",
        "outputId": "f1c67c91-f2a9-46b3-efcd-3b9030c2b654"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting torcheval\n  Obtaining dependency information for torcheval from https://files.pythonhosted.org/packages/e4/de/e7abc784b00de9d05999657d29187f1f7a3406ed10ecaf164de06482608f/torcheval-0.0.7-py3-none-any.whl.metadata\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.5.0)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
        "import cv2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "# Pytorch Imports\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch\n",
        "from torcheval.metrics.functional import multiclass_f1_score\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda import amp\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from torchvision import models\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import albumentations as A\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "# For colored terminal text\n",
        "from colorama import Fore, Back, Style\n",
        "b_ = Fore.BLUE\n",
        "sr_ = Style.RESET_ALL\n",
        "from timm.data.mixup import Mixup\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from timm.loss import SoftTargetCrossEntropy\n",
        "from torch.autograd import Variable\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:13:56.485137Z",
          "iopub.execute_input": "2023-12-07T16:13:56.485443Z",
          "iopub.status.idle": "2023-12-07T16:14:01.716830Z",
          "shell.execute_reply.started": "2023-12-07T16:13:56.485418Z",
          "shell.execute_reply": "2023-12-07T16:14:01.716075Z"
        },
        "trusted": true,
        "id": "f3i121AvEWxm",
        "outputId": "f932c0e8-386a-4456-c300-bda7074a8ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CONFIGURATION**"
      ],
      "metadata": {
        "id": "Nt86TgM_EWxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You can get the model from [here](https://github.com/huggingface/pytorch-image-models/tree/main/timm/models)**"
      ],
      "metadata": {
        "id": "GN0ZYndHEWxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "path = '/tf'\n",
        "batch_size = 16\n",
        "use_amp = True\n",
        "epochs = 30\n",
        "lr = 0.0001\n",
        "num_classes = 6\n",
        "CLIP_GRAD = 5.0\n",
        "seed = 42\n",
        "image_size = 1024\n",
        "n_fold = 6\n",
        "fold = 0\n",
        "model_name = 'convnext_base'\n",
        "PCH_TEST_DIR = '/tf/train'\n",
        "WSI_TEST_DIR = '/tf/image_train'\n",
        "classes = ['CC', 'EC', 'HGSC', 'LGSC', 'MC', 'Normal']\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
        "device_ids = list(range(torch.cuda.device_count()))\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:01.717855Z",
          "iopub.execute_input": "2023-12-07T16:14:01.718145Z",
          "iopub.status.idle": "2023-12-07T16:14:01.769337Z",
          "shell.execute_reply.started": "2023-12-07T16:14:01.718120Z",
          "shell.execute_reply": "2023-12-07T16:14:01.768428Z"
        },
        "trusted": true,
        "id": "P9I3P8jJEWxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(seed)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:01.771754Z",
          "iopub.execute_input": "2023-12-07T16:14:01.772403Z",
          "iopub.status.idle": "2023-12-07T16:14:01.780957Z",
          "shell.execute_reply.started": "2023-12-07T16:14:01.772370Z",
          "shell.execute_reply": "2023-12-07T16:14:01.780250Z"
        },
        "trusted": true,
        "id": "1iIGWcfSEWxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA PREPROCESS**"
      ],
      "metadata": {
        "id": "oHqvBaXEEWxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UBCDataset(Dataset):\n",
        "    def __init__(self, root, transforms=None):\n",
        "        self.root = root\n",
        "        self.file_names = root['file_path'].values\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # Assuming your labels are in a column named 'label' in your DataFrame\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.labels = self.label_encoder.fit_transform(self.root['label'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.root)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.file_names[index]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)[\"image\"]\n",
        "\n",
        "        return {\n",
        "            'image': img,\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:01.782106Z",
          "iopub.execute_input": "2023-12-07T16:14:01.782838Z",
          "iopub.status.idle": "2023-12-07T16:14:01.794271Z",
          "shell.execute_reply.started": "2023-12-07T16:14:01.782806Z",
          "shell.execute_reply": "2023-12-07T16:14:01.793442Z"
        },
        "trusted": true,
        "id": "gXtENdApEWxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    \"train\": A.Compose([\n",
        "        A.Resize(image_size, image_size),\n",
        "        A.ShiftScaleRotate(shift_limit=0.1,\n",
        "                           scale_limit=0.15,\n",
        "                           rotate_limit=60,\n",
        "                           p=0.5),\n",
        "        A.HueSaturationValue(\n",
        "                hue_shift_limit=0.2,\n",
        "                sat_shift_limit=0.2,\n",
        "                val_shift_limit=0.2,\n",
        "                p=0.5\n",
        "            ),\n",
        "        A.RandomBrightnessContrast(\n",
        "                brightness_limit=(-0.1,0.1),\n",
        "                contrast_limit=(-0.1, 0.1),\n",
        "                p=0.5\n",
        "            ),\n",
        "        A.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "                max_pixel_value=255.0,\n",
        "                p=1.0\n",
        "            ),\n",
        "        ToTensorV2()], p=1.),\n",
        "\n",
        "    \"valid\": A.Compose([\n",
        "        A.Resize(image_size, image_size),\n",
        "        A.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "                max_pixel_value=255.0,\n",
        "                p=1.0\n",
        "            ),\n",
        "        ToTensorV2()], p=1.)\n",
        "}\n",
        "mixup_fn = Mixup(\n",
        "        mixup_alpha=0.8, cutmix_alpha=1.0, cutmix_minmax=None,\n",
        "        prob=0.1, switch_prob=0.5, mode='batch',\n",
        "        label_smoothing=0.1, num_classes=num_classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:01.795310Z",
          "iopub.execute_input": "2023-12-07T16:14:01.795576Z",
          "iopub.status.idle": "2023-12-07T16:14:01.806949Z",
          "shell.execute_reply.started": "2023-12-07T16:14:01.795553Z",
          "shell.execute_reply": "2023-12-07T16:14:01.806064Z"
        },
        "trusted": true,
        "id": "oxe-eXTmEWxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOAD DATA**"
      ],
      "metadata": {
        "id": "bEgnGRxKEWxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(df,fold):\n",
        "    skf = StratifiedKFold(n_splits=n_fold)\n",
        "    for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.label)):\n",
        "          df.loc[val_ , \"kfold\"] = int(fold)\n",
        "\n",
        "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = UBCDataset(df_train, transforms=data_transforms[\"train\"])\n",
        "    valid_dataset = UBCDataset(df_valid, transforms=data_transforms[\"valid\"])\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    test_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    return train_loader,test_loader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:01.808106Z",
          "iopub.execute_input": "2023-12-07T16:14:01.808792Z",
          "iopub.status.idle": "2023-12-07T16:14:01.820665Z",
          "shell.execute_reply.started": "2023-12-07T16:14:01.808759Z",
          "shell.execute_reply": "2023-12-07T16:14:01.819816Z"
        },
        "trusted": true,
        "id": "-ZfgiVzNEWxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_file_path(image_id):\n",
        "    if os.path.exists(f\"{PCH_TEST_DIR}/{image_id}.png\"):\n",
        "        return f\"{PCH_TEST_DIR}/{image_id}.png\"\n",
        "    else:\n",
        "        return f\"{WSI_TEST_DIR}/{image_id}.png\"\n",
        "df = pd.read_csv(f\"{path}/patch_out.csv\")\n",
        "df['file_path'] = df['image_id'].apply(get_test_file_path)\n",
        "train_loader,test_loader = get_dataloader(df, fold)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:01.821742Z",
          "iopub.execute_input": "2023-12-07T16:14:01.822412Z",
          "iopub.status.idle": "2023-12-07T16:14:02.721049Z",
          "shell.execute_reply.started": "2023-12-07T16:14:01.822380Z",
          "shell.execute_reply": "2023-12-07T16:14:02.720361Z"
        },
        "trusted": true,
        "id": "pdL8D5OLEWxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL BLOCK**"
      ],
      "metadata": {
        "id": "NL45dp8MEWxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling strategy to replace Max pooling and Average pooling\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super(GeM, self).__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1)*p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gem(x, p=self.p, eps=self.eps)\n",
        "\n",
        "    def gem(self, x, p=3, eps=1e-6):\n",
        "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \\\n",
        "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
        "                ', ' + 'eps=' + str(self.eps) + ')'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:02.722050Z",
          "iopub.execute_input": "2023-12-07T16:14:02.722330Z",
          "iopub.status.idle": "2023-12-07T16:14:02.730466Z",
          "shell.execute_reply.started": "2023-12-07T16:14:02.722306Z",
          "shell.execute_reply": "2023-12-07T16:14:02.729492Z"
        },
        "trusted": true,
        "id": "HhGBEsMbEWxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UBCModel(nn.Module):\n",
        "    def __init__(self, model_name, num_classes, pretrained=True, checkpoint_path=None):\n",
        "        super(UBCModel, self).__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n",
        "        in_features = self.model.head.in_features\n",
        "        self.model.head = nn.Identity()\n",
        "        self.pooling = GeM()\n",
        "        self.linear = nn.Linear(in_features, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, images):\n",
        "        features = self.model(images)\n",
        "        pooled_features = self.pooling(features).flatten(1)\n",
        "        output = self.linear(pooled_features)\n",
        "#         if self.softmax is not None:\n",
        "#             output = self.softmax(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "model = UBCModel(model_name, num_classes)\n",
        "\n",
        "# model = models.resnet18()\n",
        "# num_fcin = model.fc.in_features\n",
        "# model.fc = nn.Linear(num_fcin, num_classes)\n",
        "\n",
        "# model = UBCModel(model_name, num_classes)\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(f\"Using {torch.cuda.device_count()} GPUs for training.\")\n",
        "    model = nn.DataParallel(model, device_ids=device_ids)\n",
        "model.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:02.734266Z",
          "iopub.execute_input": "2023-12-07T16:14:02.735165Z",
          "iopub.status.idle": "2023-12-07T16:14:15.473320Z",
          "shell.execute_reply.started": "2023-12-07T16:14:02.735132Z",
          "shell.execute_reply": "2023-12-07T16:14:15.472353Z"
        },
        "trusted": true,
        "id": "_u-WOxWMEWxo",
        "outputId": "3b3f19cf-b586-410a-a296-8806a9021a38",
        "colab": {
          "referenced_widgets": [
            "28450be20a7446bf8250dea7e5631a5d"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading model.safetensors:   0%|          | 0.00/354M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28450be20a7446bf8250dea7e5631a5d"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "UBCModel(\n  (model): ConvNeXt(\n    (stem): Sequential(\n      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n      (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n    )\n    (stages): Sequential(\n      (0): ConvNeXtStage(\n        (downsample): Identity()\n        (blocks): Sequential(\n          (0): ConvNeXtBlock(\n            (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n            (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=128, out_features=512, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=512, out_features=128, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (1): ConvNeXtBlock(\n            (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n            (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=128, out_features=512, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=512, out_features=128, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (2): ConvNeXtBlock(\n            (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n            (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=128, out_features=512, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=512, out_features=128, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n        )\n      )\n      (1): ConvNeXtStage(\n        (downsample): Sequential(\n          (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n          (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n        )\n        (blocks): Sequential(\n          (0): ConvNeXtBlock(\n            (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (1): ConvNeXtBlock(\n            (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (2): ConvNeXtBlock(\n            (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n        )\n      )\n      (2): ConvNeXtStage(\n        (downsample): Sequential(\n          (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n          (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n        )\n        (blocks): Sequential(\n          (0): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (1): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (2): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (3): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (4): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (5): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (6): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (7): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (8): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (9): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (10): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (11): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (12): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (13): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (14): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (15): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (16): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (17): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (18): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (19): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (20): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (21): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (22): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (23): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (24): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (25): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (26): ConvNeXtBlock(\n            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n        )\n      )\n      (3): ConvNeXtStage(\n        (downsample): Sequential(\n          (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n          (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n        )\n        (blocks): Sequential(\n          (0): ConvNeXtBlock(\n            (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (1): ConvNeXtBlock(\n            (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n          (2): ConvNeXtBlock(\n            (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n              (act): GELU()\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (shortcut): Identity()\n            (drop_path): Identity()\n          )\n        )\n      )\n    )\n    (norm_pre): Identity()\n    (head): Identity()\n  )\n  (pooling): GeM(p=3.0000, eps=1e-06)\n  (linear): Linear(in_features=1024, out_features=5, bias=True)\n  (softmax): Softmax(dim=1)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OPTIMIZER**"
      ],
      "metadata": {
        "id": "-uwXdQpIEWxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = nn.DataParallel(model, device_ids=device_ids)\n",
        "\n",
        "criterion = SoftTargetCrossEntropy()\n",
        "val_criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "optimizer = optim.AdamW(model.parameters(),lr=lr)\n",
        "cosine_schedule = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=20, eta_min=1e-6)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:15.474557Z",
          "iopub.execute_input": "2023-12-07T16:14:15.474856Z",
          "iopub.status.idle": "2023-12-07T16:14:15.482202Z",
          "shell.execute_reply.started": "2023-12-07T16:14:15.474831Z",
          "shell.execute_reply": "2023-12-07T16:14:15.481288Z"
        },
        "trusted": true,
        "id": "_5LIEMJFEWxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_dp=True\n",
        "if use_amp:\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    if torch.cuda.device_count() > 1 and use_dp:\n",
        "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "        model = torch.nn.DataParallel(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:15.483442Z",
          "iopub.execute_input": "2023-12-07T16:14:15.483726Z",
          "iopub.status.idle": "2023-12-07T16:14:15.495060Z",
          "shell.execute_reply.started": "2023-12-07T16:14:15.483704Z",
          "shell.execute_reply": "2023-12-07T16:14:15.494152Z"
        },
        "trusted": true,
        "id": "3i1W6dg4EWxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING MODULE**"
      ],
      "metadata": {
        "id": "ajRi6TGTEWxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train (model,epochs,optimizer,criterion,learing_rate):\n",
        "    best_epoch_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_epoch_accuracy = 0\n",
        "    best_epoch_loss = 0\n",
        "    best_epoch_f1_score = 0\n",
        "    for epoch in range(epochs):\n",
        "        torch.cuda.empty_cache()\n",
        "        all_labels = []\n",
        "        all_predictions = []\n",
        "        all_labels_val = []\n",
        "        all_predictions_val = []\n",
        "        train_epoch_loss = 0.0\n",
        "        train_class_correct = list(0. for i in range(num_classes))\n",
        "        train_class_total = list(0. for i in range(num_classes))\n",
        "        for data in tqdm(train_loader, total=len(train_loader)):\n",
        "\n",
        "            # probsum = torch.zeros((len(classes),), dtype=torch.float, device=CONFIG[\"device\"])\n",
        "            image = data['image'].to(device, dtype=torch.float)\n",
        "            label = Variable(data['label']).to(device, non_blocking=True, dtype=torch.long)\n",
        "\n",
        "            if len(label) == 2:\n",
        "                image, label = mixup_fn(image, label)\n",
        "            # inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Clear optimizer graident\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Model output of each batch from train_dataset\n",
        "            output = model(image)\n",
        "            output = output.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            if use_amp:\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    batch_loss = torch.nan_to_num(criterion(output, label))\n",
        "                scaler.scale(batch_loss).backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_GRAD)\n",
        "                # Unscales gradients and calls\n",
        "                # or skips optimizer.step()\n",
        "                scaler.step(optimizer)\n",
        "                # Updates the scale for next iteration\n",
        "                scaler.update()\n",
        "            else:\n",
        "                batch_loss = criterion(output, label)\n",
        "                loss.backward()\n",
        "                # torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_GRAD)\n",
        "                optimizer.step()\n",
        "\n",
        "            # 1. Compute train_batch_loss\n",
        "            torch.cuda.synchronize()\n",
        "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
        "            train_epoch_loss += batch_loss.item()\n",
        "\n",
        "            # 2. Compute train_class_correct of each batch\n",
        "            # print(output)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            if len(label)==2:\n",
        "                _, label = torch.max(label, 1)\n",
        "            # print(predicted, label)\n",
        "            batch_correct = (predicted == label)\n",
        "            for j in range(len(label)):\n",
        "                index = label[j].item()\n",
        "                train_class_correct[index] += batch_correct[j].item()\n",
        "                train_class_total[index] += 1\n",
        "            all_labels.append(label.cpu().numpy())\n",
        "            all_predictions.append(predicted.cpu().numpy())\n",
        "\n",
        "        # Compute Loss & Acc & F1Score of training\n",
        "        all_labels = np.concatenate(all_labels)\n",
        "        all_predictions = np.concatenate(all_predictions)\n",
        "\n",
        "        train_epoch_loss = train_epoch_loss / len(train_loader)\n",
        "        train_epoch_accuracy = sum(train_class_correct) / sum(train_class_total) * 100\n",
        "        train_epoch_f1_score = f1_score(all_labels, all_predictions, average='weighted')\n",
        "        # train_conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "        print('[Epoch:%2d]' % (epoch + 1))\n",
        "        print('[Learning rate:%f]' % (lr))\n",
        "        print('Train Accuracy of All : %.3f %%' % (train_epoch_accuracy))\n",
        "        print('Train Loss of All : %.3f ' % (train_epoch_loss))\n",
        "        print('Train F1-Score of All : %.3f ' % (train_epoch_f1_score))\n",
        "        print(\"----------------------------------------\")\n",
        "\n",
        "        # Validation class correct & class total\n",
        "        val_loss = 0.0\n",
        "        val_class_correct = list(0. for i in range(num_classes))\n",
        "        val_class_total = list(0. for i in range(num_classes))\n",
        "\n",
        "        # Validation every epoch\n",
        "        with torch.no_grad():\n",
        "            # Run all Validation dataset\n",
        "            for data in tqdm(test_loader, total=len(test_loader)):\n",
        "                # probsum = torch.zeros((len(classes),), dtype=torch.float, device=CONFIG[\"device\"])\n",
        "                image = data['image'].to(device, dtype=torch.float)\n",
        "                # One batch data\n",
        "                label = data['label'].to(device, dtype=torch.long)\n",
        "                # images, labels = images.to(device), labels.to(device)\n",
        "                # Model output of each batch from Validation_dataset\n",
        "                output = model(image)\n",
        "                output = output.to(device)\n",
        "                label = label.to(device)\n",
        "                # print(output, label)\n",
        "                # 1. Compute val_batch_loss\n",
        "                batch_loss = val_criterion(output, label)\n",
        "                val_loss += batch_loss.item()\n",
        "\n",
        "                # 2. Compute val_class_correct of each batch\n",
        "                _, predicted = torch.max(output, 1)\n",
        "                batch_correct = (predicted == label).squeeze()\n",
        "                for j in range(len(label)):\n",
        "                    index = label[j].item()\n",
        "                    if len(label) == batch_size:\n",
        "                        val_class_correct[index] += batch_correct[j].item()\n",
        "                    else:\n",
        "                        val_class_correct[index] += batch_correct.item()\n",
        "                    val_class_total[index] += 1\n",
        "                all_labels_val.append(label.cpu().numpy())\n",
        "                all_predictions_val.append(predicted.cpu().numpy())\n",
        "        # print each class accurancy of  Validation\n",
        "        for i in range(num_classes):\n",
        "            label = classes[i]\n",
        "            print('Accuracy of %5s : %2d %%' % (label, 100 * val_class_correct[i] / val_class_total[i]))\n",
        "\n",
        "        all_labels_val = np.concatenate(all_labels_val)\n",
        "        all_predictions_val = np.concatenate(all_predictions_val)\n",
        "\n",
        "        # Compute Loss & Acc & F1Score of Validation\n",
        "        val_epoch_accuracy = sum(val_class_correct) / sum(val_class_total) * 100\n",
        "        val_epoch_loss = val_loss / len(test_loader)\n",
        "        val_epoch_f1_score = f1_score(all_labels_val, all_predictions_val, average='weighted')\n",
        "        val_conf_matrix = confusion_matrix(all_labels_val, all_predictions_val)\n",
        "\n",
        "        print('Validation Accuracy of All : %.3f %%' % (val_epoch_accuracy))\n",
        "        print('Validation Loss of All : %.3f ' % (val_epoch_loss))\n",
        "        print('Validation F1-Score of All : %.3f ' % (val_epoch_f1_score))\n",
        "        print(\"----------------------------------------\")\n",
        "\n",
        "        # store the best weights\n",
        "        if best_epoch_accuracy < val_epoch_accuracy:\n",
        "            print(f\"{b_}Validation Accuracy Improved ({best_epoch_accuracy} ---> {val_epoch_accuracy})\")\n",
        "            print(f\"{b_}Validation Loss Changed ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
        "            print(f\"{b_}Validation F1-Score Changed ({best_epoch_f1_score} ---> {val_epoch_f1_score})\")\n",
        "            best_epoch_accuracy = val_epoch_accuracy\n",
        "            best_epoch_loss = val_epoch_loss\n",
        "            best_epoch_f1_score = val_epoch_f1_score\n",
        "            best_epoch_model_wts = copy.deepcopy(model.state_dict())\n",
        "            PATH = \"{:}_Acc{:.2f}_Loss{:.4f}_F1-Score{:.4f}_epoch{:.2f}.bin\".format(model_name, best_epoch_accuracy, val_epoch_loss, val_epoch_f1_score, epoch)\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            # Save a model file from the current directory\n",
        "            print(f\"Model Saved{sr_}\")\n",
        "\n",
        "            # torch.save(model.state_dict(), '/tf/model.pth')\n",
        "        cosine_schedule.step()\n",
        "    print('Finished Training')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:15.496610Z",
          "iopub.execute_input": "2023-12-07T16:14:15.497348Z",
          "iopub.status.idle": "2023-12-07T16:14:15.525138Z",
          "shell.execute_reply.started": "2023-12-07T16:14:15.497322Z",
          "shell.execute_reply": "2023-12-07T16:14:15.524429Z"
        },
        "trusted": true,
        "id": "AoWsQFRBEWxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING**"
      ],
      "metadata": {
        "id": "ua735QuaEWxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model,epochs,optimizer,criterion,lr)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-07T16:14:15.526164Z",
          "iopub.execute_input": "2023-12-07T16:14:15.526529Z"
        },
        "trusted": true,
        "id": "lm-tAjF3EWxq",
        "outputId": "e6d711d2-66f3-4c68-e892-926f9bb6d3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:35<00:00,  9.33s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch: 1]\n[Learning rate:0.000100]\nTrain Accuracy of All : 41.067 %\nTrain Loss of All : 1.645 \nTrain F1-Score of All : 0.343 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.44it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC :  0 %\nAccuracy of    EC :  0 %\nAccuracy of  HGSC : 100 %\nAccuracy of  LGSC :  0 %\nAccuracy of    MC :  0 %\nValidation Accuracy of All : 41.121 %\nValidation Loss of All : 1.446 \nValidation F1-Score of All : 0.240 \n----------------------------------------\n\u001b[34mValidation Accuracy Improved (0 ---> 41.1214953271028)\n\u001b[34mValidation Loss Changed (0 ---> 1.445639889549326)\n\u001b[34mValidation F1-Score Changed (0 ---> 0.2396484495884137)\nModel Saved\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:31<00:00,  9.31s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch: 2]\n[Learning rate:0.000099]\nTrain Accuracy of All : 45.244 %\nTrain Loss of All : 1.550 \nTrain F1-Score of All : 0.405 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.44it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 25 %\nAccuracy of    EC : 40 %\nAccuracy of  HGSC : 88 %\nAccuracy of  LGSC : 11 %\nAccuracy of    MC :  0 %\nValidation Accuracy of All : 51.402 %\nValidation Loss of All : 1.291 \nValidation F1-Score of All : 0.457 \n----------------------------------------\n\u001b[34mValidation Accuracy Improved (41.1214953271028 ---> 51.4018691588785)\n\u001b[34mValidation Loss Changed (1.445639889549326 ---> 1.291483380176403)\n\u001b[34mValidation F1-Score Changed (0.2396484495884137 ---> 0.4567469269370654)\nModel Saved\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:18<00:00,  9.25s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch: 3]\n[Learning rate:0.000098]\nTrain Accuracy of All : 55.916 %\nTrain Loss of All : 1.423 \nTrain F1-Score of All : 0.528 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.45it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 95 %\nAccuracy of    EC : 36 %\nAccuracy of  HGSC : 52 %\nAccuracy of  LGSC :  0 %\nAccuracy of    MC : 22 %\nValidation Accuracy of All : 49.533 %\nValidation Loss of All : 1.434 \nValidation F1-Score of All : 0.483 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:22<00:00,  9.27s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch: 4]\n[Learning rate:0.000095]\nTrain Accuracy of All : 58.005 %\nTrain Loss of All : 1.272 \nTrain F1-Score of All : 0.561 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.45it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 50 %\nAccuracy of    EC :  4 %\nAccuracy of  HGSC : 93 %\nAccuracy of  LGSC :  0 %\nAccuracy of    MC : 22 %\nValidation Accuracy of All : 50.467 %\nValidation Loss of All : 1.281 \nValidation F1-Score of All : 0.409 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:20<00:00,  9.26s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch: 5]\n[Learning rate:0.000091]\nTrain Accuracy of All : 65.661 %\nTrain Loss of All : 1.155 \nTrain F1-Score of All : 0.646 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.43it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 40 %\nAccuracy of    EC : 32 %\nAccuracy of  HGSC : 79 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 55 %\nValidation Accuracy of All : 56.075 %\nValidation Loss of All : 1.130 \nValidation F1-Score of All : 0.572 \n----------------------------------------\n\u001b[34mValidation Accuracy Improved (51.4018691588785 ---> 56.074766355140184)\n\u001b[34mValidation Loss Changed (1.291483380176403 ---> 1.1299738986072716)\n\u001b[34mValidation F1-Score Changed (0.4567469269370654 ---> 0.5720919344963282)\nModel Saved\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:24<00:00,  9.28s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch: 6]\n[Learning rate:0.000086]\nTrain Accuracy of All : 68.677 %\nTrain Loss of All : 1.137 \nTrain F1-Score of All : 0.669 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.44it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 70 %\nAccuracy of    EC : 24 %\nAccuracy of  HGSC : 95 %\nAccuracy of  LGSC : 22 %\nAccuracy of    MC : 44 %\nValidation Accuracy of All : 63.551 %\nValidation Loss of All : 1.119 \nValidation F1-Score of All : 0.593 \n----------------------------------------\n\u001b[34mValidation Accuracy Improved (56.074766355140184 ---> 63.55140186915887)\n\u001b[34mValidation Loss Changed (1.1299738986072716 ---> 1.1185014089224514)\n\u001b[34mValidation F1-Score Changed (0.5720919344963282 ---> 0.5932743862415025)\nModel Saved\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:20<00:00,  9.26s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch: 7]\n[Learning rate:0.000080]\nTrain Accuracy of All : 78.654 %\nTrain Loss of All : 0.989 \nTrain F1-Score of All : 0.784 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.45it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 50 %\nAccuracy of    EC : 36 %\nAccuracy of  HGSC : 97 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 55 %\nValidation Accuracy of All : 66.355 %\nValidation Loss of All : 0.974 \nValidation F1-Score of All : 0.642 \n----------------------------------------\n\u001b[34mValidation Accuracy Improved (63.55140186915887 ---> 66.35514018691589)\n\u001b[34mValidation Loss Changed (1.1185014089224514 ---> 0.9736700880306738)\n\u001b[34mValidation F1-Score Changed (0.5932743862415025 ---> 0.6420991883197368)\nModel Saved\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:26<00:00,  9.29s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch: 8]\n[Learning rate:0.000073]\nTrain Accuracy of All : 83.759 %\nTrain Loss of All : 0.781 \nTrain F1-Score of All : 0.835 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.45it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 60 %\nAccuracy of    EC : 48 %\nAccuracy of  HGSC : 81 %\nAccuracy of  LGSC : 33 %\nAccuracy of    MC : 55 %\nValidation Accuracy of All : 63.551 %\nValidation Loss of All : 0.937 \nValidation F1-Score of All : 0.630 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:22<00:00,  9.27s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch: 9]\n[Learning rate:0.000066]\nTrain Accuracy of All : 84.687 %\nTrain Loss of All : 0.819 \nTrain F1-Score of All : 0.844 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.45it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 95 %\nAccuracy of    EC : 52 %\nAccuracy of  HGSC : 75 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 44 %\nValidation Accuracy of All : 68.224 %\nValidation Loss of All : 0.966 \nValidation F1-Score of All : 0.672 \n----------------------------------------\n\u001b[34mValidation Accuracy Improved (66.35514018691589 ---> 68.22429906542055)\n\u001b[34mValidation Loss Changed (0.9736700880306738 ---> 0.9657820354181307)\n\u001b[34mValidation F1-Score Changed (0.6420991883197368 ---> 0.6724638341851854)\nModel Saved\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:27<00:00,  9.29s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:10]\n[Learning rate:0.000058]\nTrain Accuracy of All : 88.863 %\nTrain Loss of All : 0.758 \nTrain F1-Score of All : 0.887 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.43it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 90 %\nAccuracy of    EC : 52 %\nAccuracy of  HGSC : 81 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 66 %\nValidation Accuracy of All : 71.963 %\nValidation Loss of All : 0.902 \nValidation F1-Score of All : 0.712 \n----------------------------------------\n\u001b[34mValidation Accuracy Improved (68.22429906542055 ---> 71.96261682242991)\n\u001b[34mValidation Loss Changed (0.9657820354181307 ---> 0.9018698457490515)\n\u001b[34mValidation F1-Score Changed (0.6724638341851854 ---> 0.7123813813953511)\nModel Saved\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:39<00:00,  9.35s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:11]\n[Learning rate:0.000051]\nTrain Accuracy of All : 92.343 %\nTrain Loss of All : 0.703 \nTrain F1-Score of All : 0.922 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.42it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 70 %\nAccuracy of    EC : 44 %\nAccuracy of  HGSC : 93 %\nAccuracy of  LGSC : 33 %\nAccuracy of    MC : 55 %\nValidation Accuracy of All : 69.159 %\nValidation Loss of All : 0.910 \nValidation F1-Score of All : 0.675 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:40<00:00,  9.35s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:12]\n[Learning rate:0.000043]\nTrain Accuracy of All : 95.360 %\nTrain Loss of All : 0.527 \nTrain F1-Score of All : 0.953 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.44it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 60 %\nAccuracy of    EC : 40 %\nAccuracy of  HGSC : 95 %\nAccuracy of  LGSC : 33 %\nAccuracy of    MC : 44 %\nValidation Accuracy of All : 66.355 %\nValidation Loss of All : 1.020 \nValidation F1-Score of All : 0.644 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:39<00:00,  9.35s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:13]\n[Learning rate:0.000035]\nTrain Accuracy of All : 94.896 %\nTrain Loss of All : 0.688 \nTrain F1-Score of All : 0.949 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.43it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 65 %\nAccuracy of    EC : 48 %\nAccuracy of  HGSC : 86 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 66 %\nValidation Accuracy of All : 68.224 %\nValidation Loss of All : 0.888 \nValidation F1-Score of All : 0.674 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:40<00:00,  9.35s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:14]\n[Learning rate:0.000028]\nTrain Accuracy of All : 96.056 %\nTrain Loss of All : 0.580 \nTrain F1-Score of All : 0.960 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.41it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 80 %\nAccuracy of    EC : 48 %\nAccuracy of  HGSC : 84 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 55 %\nValidation Accuracy of All : 69.159 %\nValidation Loss of All : 0.894 \nValidation F1-Score of All : 0.684 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:40<00:00,  9.35s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:15]\n[Learning rate:0.000021]\nTrain Accuracy of All : 95.824 %\nTrain Loss of All : 0.581 \nTrain F1-Score of All : 0.958 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.44it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 90 %\nAccuracy of    EC : 44 %\nAccuracy of  HGSC : 88 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 66 %\nValidation Accuracy of All : 72.897 %\nValidation Loss of All : 0.926 \nValidation F1-Score of All : 0.716 \n----------------------------------------\n\u001b[34mValidation Accuracy Improved (71.96261682242991 ---> 72.89719626168224)\n\u001b[34mValidation Loss Changed (0.9018698457490515 ---> 0.925753987773701)\n\u001b[34mValidation F1-Score Changed (0.7123813813953511 ---> 0.7164816795543945)\nModel Saved\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:33<00:00,  9.32s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:16]\n[Learning rate:0.000015]\nTrain Accuracy of All : 96.288 %\nTrain Loss of All : 0.507 \nTrain F1-Score of All : 0.963 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.38it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 70 %\nAccuracy of    EC : 52 %\nAccuracy of  HGSC : 88 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 66 %\nValidation Accuracy of All : 71.028 %\nValidation Loss of All : 0.880 \nValidation F1-Score of All : 0.702 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:39<00:00,  9.35s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:17]\n[Learning rate:0.000010]\nTrain Accuracy of All : 95.824 %\nTrain Loss of All : 0.491 \nTrain F1-Score of All : 0.958 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.41it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 80 %\nAccuracy of    EC : 44 %\nAccuracy of  HGSC : 88 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 66 %\nValidation Accuracy of All : 71.028 %\nValidation Loss of All : 0.913 \nValidation F1-Score of All : 0.700 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:39<00:00,  9.35s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:18]\n[Learning rate:0.000006]\nTrain Accuracy of All : 95.128 %\nTrain Loss of All : 0.571 \nTrain F1-Score of All : 0.951 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.42it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 85 %\nAccuracy of    EC : 44 %\nAccuracy of  HGSC : 88 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 66 %\nValidation Accuracy of All : 71.963 %\nValidation Loss of All : 0.916 \nValidation F1-Score of All : 0.708 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:39<00:00,  9.35s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:19]\n[Learning rate:0.000003]\nTrain Accuracy of All : 96.984 %\nTrain Loss of All : 0.589 \nTrain F1-Score of All : 0.970 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.42it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 85 %\nAccuracy of    EC : 48 %\nAccuracy of  HGSC : 88 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 66 %\nValidation Accuracy of All : 72.897 %\nValidation Loss of All : 0.901 \nValidation F1-Score of All : 0.719 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:40<00:00,  9.35s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:20]\n[Learning rate:0.000002]\nTrain Accuracy of All : 98.144 %\nTrain Loss of All : 0.524 \nTrain F1-Score of All : 0.981 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.41it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 85 %\nAccuracy of    EC : 44 %\nAccuracy of  HGSC : 88 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 66 %\nValidation Accuracy of All : 71.963 %\nValidation Loss of All : 0.905 \nValidation F1-Score of All : 0.708 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 216/216 [33:38<00:00,  9.35s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Epoch:21]\n[Learning rate:0.000001]\nTrain Accuracy of All : 97.216 %\nTrain Loss of All : 0.647 \nTrain F1-Score of All : 0.972 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 54/54 [00:22<00:00,  2.42it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy of    CC : 75 %\nAccuracy of    EC : 44 %\nAccuracy of  HGSC : 88 %\nAccuracy of  LGSC : 44 %\nAccuracy of    MC : 66 %\nValidation Accuracy of All : 70.093 %\nValidation Loss of All : 0.907 \nValidation F1-Score of All : 0.691 \n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 12%|█▏        | 25/216 [03:55<29:47,  9.36s/it]",
          "output_type": "stream"
        }
      ]
    }
  ]
}